{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning study toy Project 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백준 문제중에 Linear Algebra and Group 이라는 문제가 있다.\n",
    "\n",
    "아주 단순한 문제로 \"선형대수와 군\"(이인석, 개정판)의 사진에 있는 모든 그림의 숫자를 합하면 되는 문제다.\n",
    "\n",
    "자세한 문제는 [이곳을 참고하자](https://www.acmicpc.net/problem/15636)\n",
    "\n",
    "\n",
    "\n",
    "> 문제를 확인했다면 [\"선형대수와 군\" 책의 사진을 보자](http://image.aladin.co.kr/product/5972/77/letslook/8952117441_f.jpg)\n",
    "\n",
    "이 문제를 풀기 위해 고민하던 우리는 딥러닝 스터디에서 MNIST를 배운 기억을 떠올렸다. \n",
    "\n",
    "MNIST를 활용해서 문제를 풀어보자\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 참고로 지금부터 코드는 파이썬 3.6를 권장한다.<br>\n",
    "> 만일 주피터 노트북의 파이썬이 3.6버전이 아니라면<br>\n",
    "> conda install python=3.6 명령어를 이용하여 버전을 변경시키자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "### 이미지 가져오기\n",
    "\n",
    "우리는 선형대수와 군 책을 가지고 있지않다. 따라서 이미지를 가져와야 하는데 마우스 오른쪽 클릭하여 이미지를 가져오기엔 체면이 살지 않는다. <br>\n",
    "웹 스크래핑 실습때 배운 이미지 추출을 복습할겸 한번 가볍게 써보자\n",
    "\n",
    "참고로 이미지를 가져올 주소는 http://image.aladin.co.kr/product/5972/77/letslook/8952117441_f.jpg 를 이용하면 된다.\n",
    "\n",
    "이미지는 images 폴더 내부에 linear.jpg 라는 파일명으로 만들자.\n",
    "\n",
    "##### 참고: urllib 함수는 파이썬 내장함수이다. 별로도 설치할 필요 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "# 만일 images 폴더가 존재하지 않으면 해당 폴더를 만든다.\n",
    "if not os.path.isdir('images'):\n",
    "    os.mkdir('images')\n",
    "\n",
    "# insert your code\n",
    "\n",
    "url = \"http://image.aladin.co.kr/product/5972/77/letslook/8952117441_f.jpg\"\n",
    "img_name = \"linear\"\n",
    "urlretrieve(url, \"./images/\"+img_name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 실행시키기\n",
    "\n",
    "이미지가 제대로 가져와졌는지 실행시켜보자.<br>\n",
    "이미지를 실행시키기 위해 PIL이라는 모듈을 사용하겠다. PIL은 이미지를 가공하기 좋은 모듈이다. \n",
    "\n",
    "##### 만일 아래 코드가 실행이 되지 않는다면 다음 명령어로 모듈을 설치하기 바란다.<br>\n",
    "> conda install PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "img = Image.open(\"./images/linear.png\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지가 정상적으로 나왔다면 성공적으로 가져온 것이다. 이제 모든 준비가 끝났다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "### Image Cropping\n",
    "\n",
    "#### EXAMPLE\n",
    "이미지를 가져왔다면 이제 알맞은 크기로 잘라야 한다.<br>\n",
    "우선 간단한 예제로 이미지를 잘라보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우선 이미지를 가져온다.\n",
    "img = Image.open(\"./images/linear.png\") \n",
    "\n",
    "# 자를 이미지의 좌상단과 우하단의 (x1, y2, x2, y2) 좌표로 bounding box를 만든다.\n",
    "# 위치를 모를 경우 그림판이나 다른 툴을 이용하면 좌표를 알 수 있다.\n",
    "# 아래 좌표는 예시이다.\n",
    "area = (30, 34, 871, 745)\n",
    "\n",
    "# 선택한 좌표를 가지고 crop 함수를 이용해 자른다.\n",
    "cropped_img = img.crop(area)\n",
    "\n",
    "#자른 이미지를 확인해본다.\n",
    "cropped_img.show()\n",
    "\n",
    "#자른 이미지를 저장한다.\n",
    "path = './images/'\n",
    "name = 'test'\n",
    "cropped_img.save(path + name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "실행해보면 우리가 계산할 숫자들의 이미지가 나올 것 이다.<br>\n",
    "하지만 우리가 원하는 사진은 숫자 하나 하나 잘라야 한다.\n",
    "\n",
    "다음 사진을 보자\n",
    "<img src=\"./pic/01.PNG\" width=80%/>\n",
    "\n",
    "### 우선 위 사진 처럼 사진을 하나씩 잘라보자. 파일의 형식은 0001.png 과 같은 형식이다.\n",
    "\n",
    "#### 참고로 사진은 총  1450개 이다. 즉, 0001.png 부터 1450.png가 나와야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "def get_cropped_image():\n",
    "    img = Image.open(\"./images/linear.png\") \n",
    "    count = 1\n",
    "    s_x, s_y, dx, dy = 30, 34, 16.84, 24.55\n",
    "    for i in range(0,29):\n",
    "        for j in range(0,50):\n",
    "            cropped_img = img.crop((s_x+2, s_y+2, s_x+dx-2, s_y+dy-2))\n",
    "            cropped_img.save(path + str(count).zfill(4) + '.png')\n",
    "            s_x += dx\n",
    "            count += 1\n",
    "        s_x = 30\n",
    "        s_y += dy\n",
    "get_cropped_image()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행 후 사진이 잘 나왔는지 확인해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "### image preprocessing\n",
    "\n",
    "우리가 자른 이미지는 MNIST에 의해 훈련된 모델로 분류가 잘 될까?<br>\n",
    "거의 분류가 되지 않을 것이다. 아니 그 전에 실행이 되지 않을것이다.\n",
    "\n",
    "우리가 자른 이미지의 사이즈는(자르기에 따라 약간의 오차가 있겠지만)\n",
    " 대략 (17, 24, 3)의 픽셀로 이루어져 있다. 각각 width, height, depth의 값이다.\n",
    " \n",
    "하지만 MNIST의 데이터는 (28, 28, 1)로 사이즈가 서로 다르다.\n",
    "\n",
    "또한 이미지 주변의 테두리도 잘라내고 싶다.\n",
    "\n",
    "다음 순서로 이미지를 가공해보자.\n",
    "\n",
    "> 1. 위와 마찬가지로 이미지를 일단 자른다.\n",
    "2. 테두리의 검은 선을 자르기 위해 자른 이미지를 다시 한번 약간 자른다.\n",
    "3. Image 모듈의 함수를 이용해서 28X28의 이미지로 scaling 시킨다.\n",
    "4. depth를 1로 만들기 위해 사진을 흑백으로 변경시킨다. 이 때 convert 함수를 이용한다.\n",
    "5. MNIST는 배경이 검은색 글씨가 흰색인 사진이다. 우리의 사진도 마찬가지로 만들어주기 위해 사진의 색을 반전시키자.\n",
    "\n",
    "[모듈에 관한 자세한 설명은 이곳을 참고하자](https://pillow.readthedocs.io/en/3.1.x/reference/Image.html)\n",
    "\n",
    "\n",
    "\n",
    "실행 결과는 다음과 같다<br><br>\n",
    "<img src=\"./pic/02.PNG\" width=80%/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "# 코드가 완성됐다면 함수로 만들어서 계속 사용 할 수 있게 하자\n",
    "# 함수의 이름은 image_prep() 로 하 도록 하자.\n",
    "def image_prep():\n",
    "    count = 1\n",
    "    basewidth,hsize = 28, 28\n",
    "    s_x, s_y, dx, dy = 30, 34, 16.84, 24.55\n",
    "    for i in range(0,29):\n",
    "        for j in range(0,50):\n",
    "            cropped_img = img.crop((s_x+2, s_y+2, s_x+dx-2, s_y+dy-2))\n",
    "            cropped_img = cropped_img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "            cropped_img = cropped_img.convert('L')\n",
    "            cropped_img = cropped_img.point(lambda x: 255 if x<100 else 0, '1')\n",
    "            cropped_img.save(path + str(count).zfill(4) + '.png')\n",
    "            s_x += dx\n",
    "            count += 1\n",
    "        s_x = 30\n",
    "        s_y += dy\n",
    "image_prep()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "### softmax로 MNIST 학습시키기\n",
    "\n",
    "lab 7에서 혹은 이후 lab에서 실습한 예제를 이용해서 MNIST를 학습시키자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-5fa9e7c60500>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-6-5fa9e7c60500>:23: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "Epoch:  0001 cost =   2.902109\n",
      "Epoch:  0002 cost =   1.091179\n",
      "Epoch:  0003 cost =   0.865537\n",
      "Epoch:  0004 cost =   0.758689\n",
      "Epoch:  0005 cost =   0.692118\n",
      "Epoch:  0006 cost =   0.644991\n",
      "Epoch:  0007 cost =   0.608931\n",
      "Epoch:  0008 cost =   0.580106\n",
      "Epoch:  0009 cost =   0.556375\n",
      "Epoch:  0010 cost =   0.535950\n",
      "Epoch:  0011 cost =   0.519028\n",
      "Epoch:  0012 cost =   0.503588\n",
      "Epoch:  0013 cost =   0.490076\n",
      "Epoch:  0014 cost =   0.478281\n",
      "Epoch:  0015 cost =   0.467145\n",
      "Accuracy:  0.8907\n"
     ]
    }
   ],
   "source": [
    "# MNIST를 학습시켜보자. 복붙하지 말자\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# MNIST data image of shape 28*28 = 784\n",
    "X = tf.placeholder(tf.float32, [None,784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None,nb_classes])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "# Hypothesis (using softmax)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b )\n",
    "\n",
    "cost = tf.reduce_mean( -tf.reduce_sum(Y * tf.log(hypothesis),axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1 ).minimize(cost)\n",
    "\n",
    "# Test Model\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1),tf.arg_max(Y,1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initalize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training Cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "        print('Epoch: ', '%04d' % (epoch +1), 'cost = ', '{:9f}' .format(avg_cost))\n",
    "    print(\n",
    "        \"Accuracy: \",\n",
    "        accuracy.eval(\n",
    "            session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 모델을 이용하다 보니 정확도가 높지 않다.<br>\n",
    "\n",
    "하지만 그대로 진행한다. 대략 88%이상의 정확도면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "\n",
    "### 이미지 데이터 가져오기\n",
    "\n",
    "이미지의 리스트를 가져오기 위해서 glob 라는 함수를 사용하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# 파일이 존재하는 폴더의 위치를 정해주고 \n",
    "# 해당 위치의 모든 png file을 정렬해서 가져온다.\n",
    "glob_path = glob.glob('./images/*.png')\n",
    "test_data = []\n",
    "# 이후 test_data list에 해당 이미지를 open하여 append한다.\n",
    "for img_name in glob_path:\n",
    "    im = Image.open(img_name).convert('L')\n",
    "    test_data.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 테스트 파일을 출력해 보자.\n",
    "size가 28X28이면 알맞게 불러진 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=28x28 at 0x2114737FFD0>\n",
      "1452\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 데이터를 하나 열어보자 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test_data[3],cmap=\"Greys\",interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "\n",
    "### 이미지 테스트 해보기\n",
    "\n",
    "이미지를 테스트 해 보는 단계이다. \n",
    "\n",
    "훈련한 모델을 이용하여 모델이 제대로 분류를 하는지 확인해 보자.\n",
    "\n",
    "확인을 하기 위해 사진이 들어있는 폴더 내에 0부터 9까지의 폴더를 만들어야 한다.\n",
    "\n",
    "그리고 사진을 예측한 값의 이름을 가진 폴더에 넣게 된다.\n",
    "\n",
    "\n",
    "> 폴더 조작을 위해 shutil 모듈을 이용해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of 'trainlabel' is (10000, 784)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[node Placeholder (defined at <ipython-input-6-5fa9e7c60500>:9)  = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1080, in __init__\n    self.run()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-5fa9e7c60500>\", line 9, in <module>\n    X = tf.placeholder(tf.float32, [None,784])\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6251, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[node Placeholder (defined at <ipython-input-6-5fa9e7c60500>:9)  = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[{{node Placeholder}} = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-8026b59bf9a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m     \"\"\"\n\u001b[1;32m--> 713\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5155\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5156\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5157\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[node Placeholder (defined at <ipython-input-6-5fa9e7c60500>:9)  = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1080, in __init__\n    self.run()\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-5fa9e7c60500>\", line 9, in <module>\n    X = tf.placeholder(tf.float32, [None,784])\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6251, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\admin1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[node Placeholder (defined at <ipython-input-6-5fa9e7c60500>:9)  = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# 폴더가 존재하지 않다면 폴더를 만들자\n",
    "for i in range(10):\n",
    "    if not os.path.isdir(str(i)):\n",
    "        os.mkdir(str(i))\n",
    "# 학습한 모델을 가지고 예측을 해보자. 예측후 해당 폴더로 파일을 이동시킨다.\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None,nb_classes])\n",
    "\n",
    "#print((mnist.test.images[0]))\n",
    "\n",
    "'''\n",
    "for i in range(1,1450):\n",
    "    test = np.append(test,np.array(test_data[i]))\n",
    "print(type(test[0]))\n",
    "'''\n",
    "#test_imgs.append(np.reshape(test_data[i],(28,28)))\n",
    "#\n",
    "    \n",
    "#t_img = np.array(test_data[0]).flatten()\n",
    "\n",
    "'''\n",
    "print(mnist.test.images[0])\n",
    "print(type(mnist.test.images))\n",
    "'''\n",
    "\n",
    "print (\" shape of 'trainlabel' is %s\" % (mnist.test.images.shape,))\n",
    "X = tf.placeholder(tf.float32, [784])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Accuracy: \",accuracy.eval(session=sess, feed_dict={X: np.array(test_imgs), Y: mnist.test.labels}),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사진이 폴더에 들어가면 테스트에 성공한 것이다.\n",
    "\n",
    "이제 폴더를 열어 결과를 확인해 보자.\n",
    "\n",
    "결과가 잘 나왔으면 어떠한 기법을 사용한 것인지 잘 나오지 못하였다면 어떤 부분에서 문제가 생긴지 생각해 보자\n",
    "\n",
    "개선 할 수 있다면 개선하여 도전해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7\n",
    "\n",
    "### 초기화 하기\n",
    "\n",
    "\n",
    "테스트가 끝난 뒤 다시 테스트를 하려면 손이 많이 간다. \n",
    "\n",
    "이러한 점이 불편하게 느껴지니 자동으로 초기 상태로 돌려주는 프로그램을 만들고자 한다.\n",
    "\n",
    "우선 아쉽게도 shutil 모듈 내부에는 모든 파일을 지우는 함수가 없다.\n",
    "\n",
    "따라서 shutil의 모듈의 폴더를 지우는 함수를 이용하여 폴더를 지우고 해당 폴더를 다시 만드는 작업을 하자\n",
    "\n",
    "그리고 위에서 만든 imag_prep() 함수를 이용하여 없어진 사진도 다시 복구하자\n",
    "\n",
    "모두 다 끝난 뒤 init() 함수로 만들면 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
