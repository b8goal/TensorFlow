{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Check out https://www.tensorflow.org/get_started/minist/beginners\n",
    "# for more information about the mnist dataset\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None,784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "# 0 ~ 9 digit recognition = 10 classes\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "b1 = tf.Variable(tf.random_normal([256], stddev=0.01))\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    " \n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([256], stddev=0.01))\n",
    "L2 = tf.add(tf.matmul(L1, W2), b2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    " \n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([10], stddev=0.01))\n",
    "model = tf.add(tf.matmul(L2, W3), b3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 1.371\n",
      "Epoch: 0002 Avg. cost = 0.383\n",
      "Epoch: 0003 Avg. cost = 0.259\n",
      "Epoch: 0004 Avg. cost = 0.197\n",
      "Epoch: 0005 Avg. cost = 0.156\n",
      "Epoch: 0006 Avg. cost = 0.133\n",
      "Epoch: 0007 Avg. cost = 0.114\n",
      "Epoch: 0008 Avg. cost = 0.103\n",
      "Epoch: 0009 Avg. cost = 0.091\n",
      "Epoch: 0010 Avg. cost = 0.080\n",
      "Epoch: 0011 Avg. cost = 0.074\n",
      "Epoch: 0012 Avg. cost = 0.069\n",
      "Epoch: 0013 Avg. cost = 0.061\n",
      "Epoch: 0014 Avg. cost = 0.058\n",
      "Epoch: 0015 Avg. cost = 0.053\n",
      "Epoch: 0016 Avg. cost = 0.051\n",
      "Epoch: 0017 Avg. cost = 0.047\n",
      "Epoch: 0018 Avg. cost = 0.044\n",
      "Epoch: 0019 Avg. cost = 0.040\n",
      "Epoch: 0020 Avg. cost = 0.038\n",
      "Epoch: 0021 Avg. cost = 0.036\n",
      "Epoch: 0022 Avg. cost = 0.034\n",
      "Epoch: 0023 Avg. cost = 0.032\n",
      "Epoch: 0024 Avg. cost = 0.030\n",
      "Epoch: 0025 Avg. cost = 0.029\n",
      "Epoch: 0026 Avg. cost = 0.027\n",
      "Epoch: 0027 Avg. cost = 0.026\n",
      "Epoch: 0028 Avg. cost = 0.024\n",
      "Epoch: 0029 Avg. cost = 0.024\n",
      "Epoch: 0030 Avg. cost = 0.022\n",
      "Epoch: 0031 Avg. cost = 0.022\n",
      "Epoch: 0032 Avg. cost = 0.021\n",
      "Epoch: 0033 Avg. cost = 0.020\n",
      "Epoch: 0034 Avg. cost = 0.019\n",
      "Epoch: 0035 Avg. cost = 0.018\n",
      "Epoch: 0036 Avg. cost = 0.019\n",
      "Epoch: 0037 Avg. cost = 0.016\n",
      "Epoch: 0038 Avg. cost = 0.016\n",
      "Epoch: 0039 Avg. cost = 0.016\n",
      "Epoch: 0040 Avg. cost = 0.014\n",
      "Epoch: 0041 Avg. cost = 0.013\n",
      "Epoch: 0042 Avg. cost = 0.015\n",
      "Epoch: 0043 Avg. cost = 0.014\n",
      "Epoch: 0044 Avg. cost = 0.013\n",
      "Epoch: 0045 Avg. cost = 0.012\n",
      "Epoch: 0046 Avg. cost = 0.011\n",
      "Epoch: 0047 Avg. cost = 0.011\n",
      "Epoch: 0048 Avg. cost = 0.011\n",
      "Epoch: 0049 Avg. cost = 0.011\n",
      "Epoch: 0050 Avg. cost = 0.011\n",
      "Epoch: 0051 Avg. cost = 0.011\n",
      "Epoch: 0052 Avg. cost = 0.011\n",
      "Epoch: 0053 Avg. cost = 0.011\n",
      "Epoch: 0054 Avg. cost = 0.010\n",
      "Epoch: 0055 Avg. cost = 0.009\n",
      "Epoch: 0056 Avg. cost = 0.010\n",
      "Epoch: 0057 Avg. cost = 0.009\n",
      "Epoch: 0058 Avg. cost = 0.009\n",
      "Epoch: 0059 Avg. cost = 0.009\n",
      "Epoch: 0060 Avg. cost = 0.010\n",
      "Epoch: 0061 Avg. cost = 0.009\n",
      "Epoch: 0062 Avg. cost = 0.008\n",
      "Epoch: 0063 Avg. cost = 0.007\n",
      "Epoch: 0064 Avg. cost = 0.007\n",
      "Epoch: 0065 Avg. cost = 0.007\n",
      "Epoch: 0066 Avg. cost = 0.008\n",
      "Epoch: 0067 Avg. cost = 0.007\n",
      "Epoch: 0068 Avg. cost = 0.008\n",
      "Epoch: 0069 Avg. cost = 0.007\n",
      "Epoch: 0070 Avg. cost = 0.007\n",
      "Epoch: 0071 Avg. cost = 0.007\n",
      "Epoch: 0072 Avg. cost = 0.006\n",
      "Epoch: 0073 Avg. cost = 0.006\n",
      "Epoch: 0074 Avg. cost = 0.007\n",
      "Epoch: 0075 Avg. cost = 0.007\n",
      "Epoch: 0076 Avg. cost = 0.006\n",
      "Epoch: 0077 Avg. cost = 0.007\n",
      "Epoch: 0078 Avg. cost = 0.006\n",
      "Epoch: 0079 Avg. cost = 0.006\n",
      "Epoch: 0080 Avg. cost = 0.006\n",
      "Epoch: 0081 Avg. cost = 0.006\n",
      "Epoch: 0082 Avg. cost = 0.006\n",
      "Epoch: 0083 Avg. cost = 0.005\n",
      "Epoch: 0084 Avg. cost = 0.005\n",
      "Epoch: 0085 Avg. cost = 0.005\n",
      "Epoch: 0086 Avg. cost = 0.005\n",
      "Epoch: 0087 Avg. cost = 0.006\n",
      "Epoch: 0088 Avg. cost = 0.005\n",
      "Epoch: 0089 Avg. cost = 0.004\n",
      "Epoch: 0090 Avg. cost = 0.006\n",
      "Epoch: 0091 Avg. cost = 0.005\n",
      "Epoch: 0092 Avg. cost = 0.005\n",
      "Epoch: 0093 Avg. cost = 0.005\n",
      "Epoch: 0094 Avg. cost = 0.005\n",
      "Epoch: 0095 Avg. cost = 0.006\n",
      "Epoch: 0096 Avg. cost = 0.005\n",
      "Epoch: 0097 Avg. cost = 0.005\n",
      "Epoch: 0098 Avg. cost = 0.004\n",
      "Epoch: 0099 Avg. cost = 0.005\n",
      "Epoch: 0100 Avg. cost = 0.005\n",
      "정확도: 98.32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#parameters\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize Tensorflow Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range (training_epochs):\n",
    "        total_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val = sess.run([optimizer, cost],feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})\n",
    "            total_cost += cost_val\n",
    "        \n",
    "        print('Epoch:', '%04d' % (epoch + 1),'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    print('정확도: %.2f' % sess.run(accuracy * 100,\n",
    "        feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    " \n",
    "    labels = sess.run(model,\n",
    "        feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1})\n",
    "    fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.placeholder(tf.float32, shape=(None))\n",
    "digits = []\n",
    "for digit_location in digits_list:\n",
    "    digits.append(scipy.ndimage.imread(digit_location))\n",
    "digits = np.asarray(digits)\n",
    "feed_dict = {img : digits}\n",
    "sess.run(model, feed_dict = feed_dict)\n",
    "\n",
    "for i in range(10):\n",
    "    fig = plt.figure()\n",
    "    # 2x5 그리드에 i+1번째 subplot을 추가하고 얻어옴\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    # x, y 축의 지점 표시를 안함\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "\n",
    "    # subplot의 제목을 i번째 결과에 해당하는 숫자로 설정\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "\n",
    "    # 입력으로 사용한 i번째 테스트 이미지를 28x28로 재배열하고\n",
    "    # 이 2차원 배열을 그레이스케일 이미지로 출력\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)),cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
